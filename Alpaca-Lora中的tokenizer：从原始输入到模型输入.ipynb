{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a427f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beb8ee0",
   "metadata": {},
   "source": [
    "**加载`tokenizer`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26af8763",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(\"yahma/llama-13b-hf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b76f56",
   "metadata": {},
   "source": [
    "**加载数据**\n",
    "\n",
    "样例数据：\n",
    "```json\n",
    "{\n",
    "    \"instruction\": \"给出一座英国城市，写一个对主要旅游景点的描述\",\n",
    "    \"input\": \"伦敦\",\n",
    "    \"output\": \"伦敦最著名的旅游景点之一是伦敦塔。 这座历史悠久的城堡建于1000多年前，曾经用作监狱、皇家住所和堡垒长达600多年。 今天，游客可以探索宏伟的大厅、中世纪房间和白塔式建筑，并参观皇冠上的珠宝、传说中的大乌鸦，并查看博物馆里的各种各样的有趣物品。\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8429398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "demo_data = [\n",
    "    {\n",
    "        \"instruction\": \"给出一座英国城市，写一个对主要旅游景点的描述\",\n",
    "        \"input\": \"伦敦\",\n",
    "        \"output\": \"伦敦最著名的旅游景点之一是伦敦塔。 这座历史悠久的城堡建于1000多年前，曾经用作监狱、皇家住所和堡垒长达600多年。 今天，游客可以探索宏伟的大厅、中世纪房间和白塔式建筑，并参观皇冠上的珠宝、传说中的大乌鸦，并查看博物馆里的各种各样的有趣物品。\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"给出一座英国城市，写一个对主要旅游景点的描述\",\n",
    "        \"input\": \"伦敦\",\n",
    "        \"output\": \"伦敦最著名的旅游景点之一是伦敦塔。 这座历史悠久的城堡建于1000多年前，曾经用作监狱、皇家住所和堡垒长达600多年.\"\n",
    "    }\n",
    "]\n",
    "data = Dataset.from_list(demo_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c79794c",
   "metadata": {},
   "source": [
    "**打印数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f62950f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': '给出一座英国城市，写一个对主要旅游景点的描述',\n",
       " 'input': '伦敦',\n",
       " 'output': '伦敦最著名的旅游景点之一是伦敦塔。 这座历史悠久的城堡建于1000多年前，曾经用作监狱、皇家住所和堡垒长达600多年。 今天，游客可以探索宏伟的大厅、中世纪房间和白塔式建筑，并参观皇冠上的珠宝、传说中的大乌鸦，并查看博物馆里的各种各样的有趣物品。'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3628319b",
   "metadata": {},
   "source": [
    "**定义Prompter**\n",
    "\n",
    "`Prompter`是用来把原始数据镶嵌到一个模板里面，让最终输入到模型里面的数据更有规范。alpaca-lora中的Prompter代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49ff8100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import json\n",
    "from typing import Union\n",
    "class Prompter(object):\n",
    "    # __slots__的作用：Prompter 只允许添加template和_verbose属性\n",
    "    # _verbose是True的时候会打印一些日子信息；\n",
    "    # 所以最核心的就是template\n",
    "    __slots__ = (\"template\", \"_verbose\")\n",
    "\n",
    "    def __init__(self, template_name: str = \"\", verbose: bool = False):\n",
    "        self._verbose = verbose\n",
    "        if not template_name:\n",
    "            # Enforce the default here, so the constructor can be called with '' and will not break.\n",
    "            template_name = \"alpaca\"\n",
    "        file_name = osp.join(\"templates\", f\"{template_name}.json\")\n",
    "        if not osp.exists(file_name):\n",
    "            raise ValueError(f\"Can't read {file_name}\")\n",
    "        with open(file_name) as fp:\n",
    "            self.template = json.load(fp)\n",
    "        if self._verbose:\n",
    "            print(\n",
    "                f\"Using prompt template {template_name}: {self.template['description']}\"\n",
    "            )\n",
    "\n",
    "    def generate_prompt(\n",
    "        self,\n",
    "        instruction: str,\n",
    "        input: Union[None, str] = None,\n",
    "        label: Union[None, str] = None,\n",
    "    ) -> str:\n",
    "        # returns the full prompt from instruction and optional input\n",
    "        # if a label (=response, =output) is provided, it's also appended.\n",
    "        if input:\n",
    "            res = self.template[\"prompt_input\"].format(\n",
    "                instruction=instruction, input=input\n",
    "            )\n",
    "        else:\n",
    "            res = self.template[\"prompt_no_input\"].format(\n",
    "                instruction=instruction\n",
    "            )\n",
    "        if label:\n",
    "            res = f\"{res}{label}\"\n",
    "        if self._verbose:\n",
    "            print(res)\n",
    "        return res\n",
    "\n",
    "    def get_response(self, output: str) -> str:\n",
    "        return output.split(self.template[\"response_split\"])[1].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d31ccf",
   "metadata": {},
   "source": [
    "Prompter的作用是给定`instruction`, `input`和`output`，生成一个模版式的字符串，这个字符串会被送入到模型中去；\n",
    "\n",
    "所以首先我们需要一个模版，来描述一下任务；\n",
    "\n",
    "在Prompter中，默认的`template_name`是`alpaca`，所以对应的模版就是`templates/alpaca.json`中所写的内容，我们将其打印出来看看："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84d2c534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"description\": \"Template used by Alpaca-LoRA.\",\n",
      "  \"prompt_input\": \"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\\n\",\n",
      "  \"prompt_no_input\": \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{instruction}\\n\\n### Response:\\n\",\n",
      "  \"response_split\": \"### Response:\"\n",
      "}\n",
      "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{instruction}\n",
      "\n",
      "### Input:\n",
      "{input}\n",
      "\n",
      "### Response:\n",
      "\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{instruction}\n",
      "\n",
      "### Response:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "template = json.load(open(\"templates/alpaca.json\"))\n",
    "print(json.dumps(template, indent=2, ensure_ascii=False))\n",
    "print(template['prompt_input'])\n",
    "print(template['prompt_no_input'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed7d49a",
   "metadata": {},
   "source": [
    "所以模版中包含四个字段：\n",
    "\n",
    "- description： 用来描述这个模版是啥模板的，不会在训练的时候加入到输入中去；\n",
    "- prompt_input：如果原始数据的字段中有`input`这个字段，就是它对应的`prompt`\n",
    "- prompt_no_input：如果原始数据的字段中没有`input`这个字段，就是它对应的`prompt`\n",
    "- response_split：咋知道哪儿是输入的部分，哪儿是`response`，这个就是在模型训练好，用来生成文本的时候，根据这个字段的内容把模型的输出给切开，从而得到想要的`response`\n",
    "\n",
    "首先，把`instruction`和`input`填充到这个模板里面，（如果没有`input`，使用不带input的prompt，填充`instruction`就可以了。）\n",
    "\n",
    "其次，在训练的时候，会把原始输入的json里面的`output`字段的内容和上面填充的文本直接拼起来。返回即可。\n",
    "\n",
    "用上面的例子的话，返回的结果长这样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbf50996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "给出一座英国城市，写一个对主要旅游景点的描述\n",
      "\n",
      "### Input:\n",
      "伦敦\n",
      "\n",
      "### Response:\n",
      "伦敦最著名的旅游景点之一是伦敦塔。 这座历史悠久的城堡建于1000多年前，曾经用作监狱、皇家住所和堡垒长达600多年。 今天，游客可以探索宏伟的大厅、中世纪房间和白塔式建筑，并参观皇冠上的珠宝、传说中的大乌鸦，并查看博物馆里的各种各样的有趣物品。\n"
     ]
    }
   ],
   "source": [
    "instruction, input, output = data[0]['instruction'], data[0]['input'], data[0]['output']\n",
    "print(template['prompt_input'].format(instruction=instruction, input=input)+output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1abe32",
   "metadata": {},
   "source": [
    "**这个就是加入了模板之后，输入到模型中去的样子。**\n",
    "\n",
    "下一步我们需要做的时候，是去做tokenize。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7d602f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompter = Prompter(template_name='alpaca')\n",
    "train_on_inputs = True # 是否让 加上了instruction和input 的模板的部分参与训练，如果是False的话，就只有output的部分参与训练；\n",
    "add_eos_token = True\n",
    "cutoff_len = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c6f3208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(prompt, add_eos_token=True):\n",
    "    # there's probably a way to do this with the tokenizer settings\n",
    "    # but again, gotta move fast\n",
    "    result = tokenizer(\n",
    "        prompt,\n",
    "        truncation=True,\n",
    "        max_length=cutoff_len,\n",
    "        padding=False,\n",
    "        return_tensors=None,\n",
    "    )\n",
    "    if (\n",
    "        result[\"input_ids\"][-1] != tokenizer.eos_token_id\n",
    "        and len(result[\"input_ids\"]) < cutoff_len\n",
    "        and add_eos_token\n",
    "    ):\n",
    "        result[\"input_ids\"].append(tokenizer.eos_token_id)\n",
    "        result[\"attention_mask\"].append(1)\n",
    "\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ee44639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_tokenize_prompt(data_point):\n",
    "    full_prompt = prompter.generate_prompt(\n",
    "        data_point[\"instruction\"],\n",
    "        data_point[\"input\"],\n",
    "        data_point[\"output\"],\n",
    "    )\n",
    "    tokenized_full_prompt = tokenize(full_prompt)\n",
    "    if not train_on_inputs:\n",
    "        user_prompt = prompter.generate_prompt(\n",
    "            data_point[\"instruction\"], data_point[\"input\"]\n",
    "        )\n",
    "        tokenized_user_prompt = tokenize(\n",
    "            user_prompt, add_eos_token=add_eos_token\n",
    "        )\n",
    "        user_prompt_len = len(tokenized_user_prompt[\"input_ids\"])\n",
    "\n",
    "        if add_eos_token:\n",
    "            user_prompt_len -= 1\n",
    "\n",
    "        tokenized_full_prompt[\"labels\"] = [\n",
    "            -100\n",
    "        ] * user_prompt_len + tokenized_full_prompt[\"labels\"][\n",
    "            user_prompt_len:\n",
    "        ]  # could be sped up, probably\n",
    "    return tokenized_full_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f8f411c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instruction: 给出一座英国城市，写一个对主要旅游景点的描述\n",
      "input: 伦敦\n",
      "output: 伦敦最著名的旅游景点之一是伦敦塔。 这座历史悠久的城堡建于1000多年前，曾经用作监狱、皇家住所和堡垒长达600多年。 今天，游客可以探索宏伟的大厅、中世纪房间和白塔式建筑，并参观皇冠上的珠宝、传说中的大乌鸦，并查看博物馆里的各种各样的有趣物品。\n",
      "input_ids: [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 31999, 30544, 30287, 31780, 31144, 30356, 30626, 30461, 30214, 31479, 30287, 30502, 30783, 30888, 30698, 233, 154, 136, 233, 187, 187, 31495, 30940, 30210, 233, 146, 146, 235, 194, 179, 13, 13, 2277, 29937, 10567, 29901, 13, 231, 191, 169, 233, 152, 169, 13, 13, 2277, 29937, 13291, 29901, 13, 231, 191, 169, 233, 152, 169, 30878, 235, 148, 154, 30548, 30210, 233, 154, 136, 233, 187, 187, 31495, 30940, 30577, 30287, 30392, 231, 191, 169, 233, 152, 169, 31831, 30267, 29871, 30810, 31780, 232, 145, 137, 30911, 233, 133, 163, 31347, 30210, 30626, 232, 163, 164, 30886, 30909, 29896, 29900, 29900, 29900, 30923, 30470, 30658, 30214, 233, 158, 193, 31412, 30406, 30732, 234, 158, 148, 234, 142, 180, 30330, 31140, 30613, 231, 192, 146, 30744, 30503, 232, 163, 164, 232, 161, 149, 31143, 31798, 29953, 29900, 29900, 30923, 30470, 30267, 29871, 31482, 30408, 30214, 233, 187, 187, 31915, 30682, 30651, 233, 145, 165, 31836, 232, 177, 146, 231, 191, 162, 30210, 30257, 232, 145, 136, 30330, 30275, 30793, 234, 189, 173, 31975, 31016, 30503, 30868, 31831, 30607, 30886, 234, 176, 148, 30214, 31666, 31125, 235, 170, 133, 31140, 232, 137, 163, 30429, 30210, 234, 146, 163, 31647, 30330, 31471, 31639, 30275, 30210, 30257, 231, 188, 143, 236, 187, 169, 30214, 31666, 31213, 31811, 31196, 30834, 236, 169, 137, 30755, 30210, 232, 147, 135, 31893, 232, 147, 135, 31819, 30210, 30417, 235, 185, 166, 30834, 31399, 30267, 2]\n",
      "attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "labels: [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 31999, 30544, 30287, 31780, 31144, 30356, 30626, 30461, 30214, 31479, 30287, 30502, 30783, 30888, 30698, 233, 154, 136, 233, 187, 187, 31495, 30940, 30210, 233, 146, 146, 235, 194, 179, 13, 13, 2277, 29937, 10567, 29901, 13, 231, 191, 169, 233, 152, 169, 13, 13, 2277, 29937, 13291, 29901, 13, 231, 191, 169, 233, 152, 169, 30878, 235, 148, 154, 30548, 30210, 233, 154, 136, 233, 187, 187, 31495, 30940, 30577, 30287, 30392, 231, 191, 169, 233, 152, 169, 31831, 30267, 29871, 30810, 31780, 232, 145, 137, 30911, 233, 133, 163, 31347, 30210, 30626, 232, 163, 164, 30886, 30909, 29896, 29900, 29900, 29900, 30923, 30470, 30658, 30214, 233, 158, 193, 31412, 30406, 30732, 234, 158, 148, 234, 142, 180, 30330, 31140, 30613, 231, 192, 146, 30744, 30503, 232, 163, 164, 232, 161, 149, 31143, 31798, 29953, 29900, 29900, 30923, 30470, 30267, 29871, 31482, 30408, 30214, 233, 187, 187, 31915, 30682, 30651, 233, 145, 165, 31836, 232, 177, 146, 231, 191, 162, 30210, 30257, 232, 145, 136, 30330, 30275, 30793, 234, 189, 173, 31975, 31016, 30503, 30868, 31831, 30607, 30886, 234, 176, 148, 30214, 31666, 31125, 235, 170, 133, 31140, 232, 137, 163, 30429, 30210, 234, 146, 163, 31647, 30330, 31471, 31639, 30275, 30210, 30257, 231, 188, 143, 236, 187, 169, 30214, 31666, 31213, 31811, 31196, 30834, 236, 169, 137, 30755, 30210, 232, 147, 135, 31893, 232, 147, 135, 31819, 30210, 30417, 235, 185, 166, 30834, 31399, 30267, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "data = data.map(generate_and_tokenize_prompt)\n",
    "for key, value in data[0].items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "218aa7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instruction: 给出一座英国城市，写一个对主要旅游景点的描述\n",
      "input: 伦敦\n",
      "output: 伦敦最著名的旅游景点之一是伦敦塔。 这座历史悠久的城堡建于1000多年前，曾经用作监狱、皇家住所和堡垒长达600多年。 今天，游客可以探索宏伟的大厅、中世纪房间和白塔式建筑，并参观皇冠上的珠宝、传说中的大乌鸦，并查看博物馆里的各种各样的有趣物品。\n",
      "input_ids: [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 31999, 30544, 30287, 31780, 31144, 30356, 30626, 30461, 30214, 31479, 30287, 30502, 30783, 30888, 30698, 233, 154, 136, 233, 187, 187, 31495, 30940, 30210, 233, 146, 146, 235, 194, 179, 13, 13, 2277, 29937, 10567, 29901, 13, 231, 191, 169, 233, 152, 169, 13, 13, 2277, 29937, 13291, 29901, 13, 231, 191, 169, 233, 152, 169, 30878, 235, 148, 154, 30548, 30210, 233, 154, 136, 233, 187, 187, 31495, 30940, 30577, 30287, 30392, 231, 191, 169, 233, 152, 169, 31831, 30267, 29871, 30810, 31780, 232, 145, 137, 30911, 233, 133, 163, 31347, 30210, 30626, 232, 163, 164, 30886, 30909, 29896, 29900, 29900, 29900, 30923, 30470, 30658, 30214, 233, 158, 193, 31412, 30406, 30732, 234, 158, 148, 234, 142, 180, 30330, 31140, 30613, 231, 192, 146, 30744, 30503, 232, 163, 164, 232, 161, 149, 31143, 31798, 29953, 29900, 29900, 30923, 30470, 30267, 29871, 31482, 30408, 30214, 233, 187, 187, 31915, 30682, 30651, 233, 145, 165, 31836, 232, 177, 146, 231, 191, 162, 30210, 30257, 232, 145, 136, 30330, 30275, 30793, 234, 189, 173, 31975, 31016, 30503, 30868, 31831, 30607, 30886, 234, 176, 148, 30214, 31666, 31125, 235, 170, 133, 31140, 232, 137, 163, 30429, 30210, 234, 146, 163, 31647, 30330, 31471, 31639, 30275, 30210, 30257, 231, 188, 143, 236, 187, 169, 30214, 31666, 31213, 31811, 31196, 30834, 236, 169, 137, 30755, 30210, 232, 147, 135, 31893, 232, 147, 135, 31819, 30210, 30417, 235, 185, 166, 30834, 31399, 30267, 2]\n",
      "attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "labels: [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 231, 191, 169, 233, 152, 169, 30878, 235, 148, 154, 30548, 30210, 233, 154, 136, 233, 187, 187, 31495, 30940, 30577, 30287, 30392, 231, 191, 169, 233, 152, 169, 31831, 30267, 29871, 30810, 31780, 232, 145, 137, 30911, 233, 133, 163, 31347, 30210, 30626, 232, 163, 164, 30886, 30909, 29896, 29900, 29900, 29900, 30923, 30470, 30658, 30214, 233, 158, 193, 31412, 30406, 30732, 234, 158, 148, 234, 142, 180, 30330, 31140, 30613, 231, 192, 146, 30744, 30503, 232, 163, 164, 232, 161, 149, 31143, 31798, 29953, 29900, 29900, 30923, 30470, 30267, 29871, 31482, 30408, 30214, 233, 187, 187, 31915, 30682, 30651, 233, 145, 165, 31836, 232, 177, 146, 231, 191, 162, 30210, 30257, 232, 145, 136, 30330, 30275, 30793, 234, 189, 173, 31975, 31016, 30503, 30868, 31831, 30607, 30886, 234, 176, 148, 30214, 31666, 31125, 235, 170, 133, 31140, 232, 137, 163, 30429, 30210, 234, 146, 163, 31647, 30330, 31471, 31639, 30275, 30210, 30257, 231, 188, 143, 236, 187, 169, 30214, 31666, 31213, 31811, 31196, 30834, 236, 169, 137, 30755, 30210, 232, 147, 135, 31893, 232, 147, 135, 31819, 30210, 30417, 235, 185, 166, 30834, 31399, 30267, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "train_on_inputs = False\n",
    "data = data.map(generate_and_tokenize_prompt)\n",
    "for key, value in data[0].items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfed1646",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e9048dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', '</s>', '<unk>']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a49cef3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 0]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99689d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duhu/anaconda3/envs/llm/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "\"LlamaTokenizer\" in transformers._import_structure[\"models.llama\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdaf5f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': '给出一座英国城市，写一个对主要旅游景点的描述',\n",
       " 'input': '伦敦',\n",
       " 'output': '伦敦最著名的旅游景点之一是伦敦塔。 这座历史悠久的城堡建于1000多年前，曾经用作监狱、皇家住所和堡垒长达600多年。 今天，游客可以探索宏伟的大厅、中世纪房间和白塔式建筑，并参观皇冠上的珠宝、传说中的大乌鸦，并查看博物馆里的各种各样的有趣物品。',\n",
       " 'input_ids': [1,\n",
       "  13866,\n",
       "  338,\n",
       "  385,\n",
       "  15278,\n",
       "  393,\n",
       "  16612,\n",
       "  263,\n",
       "  3414,\n",
       "  29892,\n",
       "  3300,\n",
       "  2859,\n",
       "  411,\n",
       "  385,\n",
       "  1881,\n",
       "  393,\n",
       "  8128,\n",
       "  4340,\n",
       "  3030,\n",
       "  29889,\n",
       "  14350,\n",
       "  263,\n",
       "  2933,\n",
       "  393,\n",
       "  7128,\n",
       "  2486,\n",
       "  1614,\n",
       "  2167,\n",
       "  278,\n",
       "  2009,\n",
       "  29889,\n",
       "  13,\n",
       "  13,\n",
       "  2277,\n",
       "  29937,\n",
       "  2799,\n",
       "  4080,\n",
       "  29901,\n",
       "  13,\n",
       "  31999,\n",
       "  30544,\n",
       "  30287,\n",
       "  31780,\n",
       "  31144,\n",
       "  30356,\n",
       "  30626,\n",
       "  30461,\n",
       "  30214,\n",
       "  31479,\n",
       "  30287,\n",
       "  30502,\n",
       "  30783,\n",
       "  30888,\n",
       "  30698,\n",
       "  233,\n",
       "  154,\n",
       "  136,\n",
       "  233,\n",
       "  187,\n",
       "  187,\n",
       "  31495,\n",
       "  30940,\n",
       "  30210,\n",
       "  233,\n",
       "  146,\n",
       "  146,\n",
       "  235,\n",
       "  194,\n",
       "  179,\n",
       "  13,\n",
       "  13,\n",
       "  2277,\n",
       "  29937,\n",
       "  10567,\n",
       "  29901,\n",
       "  13,\n",
       "  231,\n",
       "  191,\n",
       "  169,\n",
       "  233,\n",
       "  152,\n",
       "  169,\n",
       "  13,\n",
       "  13,\n",
       "  2277,\n",
       "  29937,\n",
       "  13291,\n",
       "  29901,\n",
       "  13,\n",
       "  231,\n",
       "  191,\n",
       "  169,\n",
       "  233,\n",
       "  152,\n",
       "  169,\n",
       "  30878,\n",
       "  235,\n",
       "  148,\n",
       "  154,\n",
       "  30548,\n",
       "  30210,\n",
       "  233,\n",
       "  154,\n",
       "  136,\n",
       "  233,\n",
       "  187,\n",
       "  187,\n",
       "  31495,\n",
       "  30940,\n",
       "  30577,\n",
       "  30287,\n",
       "  30392,\n",
       "  231,\n",
       "  191,\n",
       "  169,\n",
       "  233,\n",
       "  152,\n",
       "  169,\n",
       "  31831,\n",
       "  30267,\n",
       "  29871,\n",
       "  30810,\n",
       "  31780,\n",
       "  232,\n",
       "  145,\n",
       "  137,\n",
       "  30911,\n",
       "  233,\n",
       "  133,\n",
       "  163,\n",
       "  31347,\n",
       "  30210,\n",
       "  30626,\n",
       "  232,\n",
       "  163,\n",
       "  164,\n",
       "  30886,\n",
       "  30909,\n",
       "  29896,\n",
       "  29900,\n",
       "  29900,\n",
       "  29900,\n",
       "  30923,\n",
       "  30470,\n",
       "  30658,\n",
       "  30214,\n",
       "  233,\n",
       "  158,\n",
       "  193,\n",
       "  31412,\n",
       "  30406,\n",
       "  30732,\n",
       "  234,\n",
       "  158,\n",
       "  148,\n",
       "  234,\n",
       "  142,\n",
       "  180,\n",
       "  30330,\n",
       "  31140,\n",
       "  30613,\n",
       "  231,\n",
       "  192,\n",
       "  146,\n",
       "  30744,\n",
       "  30503,\n",
       "  232,\n",
       "  163,\n",
       "  164,\n",
       "  232,\n",
       "  161,\n",
       "  149,\n",
       "  31143,\n",
       "  31798,\n",
       "  29953,\n",
       "  29900,\n",
       "  29900,\n",
       "  30923,\n",
       "  30470,\n",
       "  30267,\n",
       "  29871,\n",
       "  31482,\n",
       "  30408,\n",
       "  30214,\n",
       "  233,\n",
       "  187,\n",
       "  187,\n",
       "  31915,\n",
       "  30682,\n",
       "  30651,\n",
       "  233,\n",
       "  145,\n",
       "  165,\n",
       "  31836,\n",
       "  232,\n",
       "  177,\n",
       "  146,\n",
       "  231,\n",
       "  191,\n",
       "  162,\n",
       "  30210,\n",
       "  30257,\n",
       "  232,\n",
       "  145,\n",
       "  136,\n",
       "  30330,\n",
       "  30275,\n",
       "  30793,\n",
       "  234,\n",
       "  189,\n",
       "  173,\n",
       "  31975,\n",
       "  31016,\n",
       "  30503,\n",
       "  30868,\n",
       "  31831,\n",
       "  30607,\n",
       "  30886,\n",
       "  234,\n",
       "  176,\n",
       "  148,\n",
       "  30214,\n",
       "  31666,\n",
       "  31125,\n",
       "  235,\n",
       "  170,\n",
       "  133,\n",
       "  31140,\n",
       "  232,\n",
       "  137,\n",
       "  163,\n",
       "  30429,\n",
       "  30210,\n",
       "  234,\n",
       "  146,\n",
       "  163,\n",
       "  31647,\n",
       "  30330,\n",
       "  31471,\n",
       "  31639,\n",
       "  30275,\n",
       "  30210,\n",
       "  30257,\n",
       "  231,\n",
       "  188,\n",
       "  143,\n",
       "  236,\n",
       "  187,\n",
       "  169,\n",
       "  30214,\n",
       "  31666,\n",
       "  31213,\n",
       "  31811,\n",
       "  31196,\n",
       "  30834,\n",
       "  236,\n",
       "  169,\n",
       "  137,\n",
       "  30755,\n",
       "  30210,\n",
       "  232,\n",
       "  147,\n",
       "  135,\n",
       "  31893,\n",
       "  232,\n",
       "  147,\n",
       "  135,\n",
       "  31819,\n",
       "  30210,\n",
       "  30417,\n",
       "  235,\n",
       "  185,\n",
       "  166,\n",
       "  30834,\n",
       "  31399,\n",
       "  30267,\n",
       "  2],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'labels': [-100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  231,\n",
       "  191,\n",
       "  169,\n",
       "  233,\n",
       "  152,\n",
       "  169,\n",
       "  30878,\n",
       "  235,\n",
       "  148,\n",
       "  154,\n",
       "  30548,\n",
       "  30210,\n",
       "  233,\n",
       "  154,\n",
       "  136,\n",
       "  233,\n",
       "  187,\n",
       "  187,\n",
       "  31495,\n",
       "  30940,\n",
       "  30577,\n",
       "  30287,\n",
       "  30392,\n",
       "  231,\n",
       "  191,\n",
       "  169,\n",
       "  233,\n",
       "  152,\n",
       "  169,\n",
       "  31831,\n",
       "  30267,\n",
       "  29871,\n",
       "  30810,\n",
       "  31780,\n",
       "  232,\n",
       "  145,\n",
       "  137,\n",
       "  30911,\n",
       "  233,\n",
       "  133,\n",
       "  163,\n",
       "  31347,\n",
       "  30210,\n",
       "  30626,\n",
       "  232,\n",
       "  163,\n",
       "  164,\n",
       "  30886,\n",
       "  30909,\n",
       "  29896,\n",
       "  29900,\n",
       "  29900,\n",
       "  29900,\n",
       "  30923,\n",
       "  30470,\n",
       "  30658,\n",
       "  30214,\n",
       "  233,\n",
       "  158,\n",
       "  193,\n",
       "  31412,\n",
       "  30406,\n",
       "  30732,\n",
       "  234,\n",
       "  158,\n",
       "  148,\n",
       "  234,\n",
       "  142,\n",
       "  180,\n",
       "  30330,\n",
       "  31140,\n",
       "  30613,\n",
       "  231,\n",
       "  192,\n",
       "  146,\n",
       "  30744,\n",
       "  30503,\n",
       "  232,\n",
       "  163,\n",
       "  164,\n",
       "  232,\n",
       "  161,\n",
       "  149,\n",
       "  31143,\n",
       "  31798,\n",
       "  29953,\n",
       "  29900,\n",
       "  29900,\n",
       "  30923,\n",
       "  30470,\n",
       "  30267,\n",
       "  29871,\n",
       "  31482,\n",
       "  30408,\n",
       "  30214,\n",
       "  233,\n",
       "  187,\n",
       "  187,\n",
       "  31915,\n",
       "  30682,\n",
       "  30651,\n",
       "  233,\n",
       "  145,\n",
       "  165,\n",
       "  31836,\n",
       "  232,\n",
       "  177,\n",
       "  146,\n",
       "  231,\n",
       "  191,\n",
       "  162,\n",
       "  30210,\n",
       "  30257,\n",
       "  232,\n",
       "  145,\n",
       "  136,\n",
       "  30330,\n",
       "  30275,\n",
       "  30793,\n",
       "  234,\n",
       "  189,\n",
       "  173,\n",
       "  31975,\n",
       "  31016,\n",
       "  30503,\n",
       "  30868,\n",
       "  31831,\n",
       "  30607,\n",
       "  30886,\n",
       "  234,\n",
       "  176,\n",
       "  148,\n",
       "  30214,\n",
       "  31666,\n",
       "  31125,\n",
       "  235,\n",
       "  170,\n",
       "  133,\n",
       "  31140,\n",
       "  232,\n",
       "  137,\n",
       "  163,\n",
       "  30429,\n",
       "  30210,\n",
       "  234,\n",
       "  146,\n",
       "  163,\n",
       "  31647,\n",
       "  30330,\n",
       "  31471,\n",
       "  31639,\n",
       "  30275,\n",
       "  30210,\n",
       "  30257,\n",
       "  231,\n",
       "  188,\n",
       "  143,\n",
       "  236,\n",
       "  187,\n",
       "  169,\n",
       "  30214,\n",
       "  31666,\n",
       "  31213,\n",
       "  31811,\n",
       "  31196,\n",
       "  30834,\n",
       "  236,\n",
       "  169,\n",
       "  137,\n",
       "  30755,\n",
       "  30210,\n",
       "  232,\n",
       "  147,\n",
       "  135,\n",
       "  31893,\n",
       "  232,\n",
       "  147,\n",
       "  135,\n",
       "  31819,\n",
       "  30210,\n",
       "  30417,\n",
       "  235,\n",
       "  185,\n",
       "  166,\n",
       "  30834,\n",
       "  31399,\n",
       "  30267,\n",
       "  2]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8090002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': '给出一座英国城市，写一个对主要旅游景点的描述',\n",
       " 'input': '伦敦',\n",
       " 'output': '伦敦最著名的旅游景点之一是伦敦塔。 这座历史悠久的城堡建于1000多年前，曾经用作监狱、皇家住所和堡垒长达600多年.',\n",
       " 'input_ids': [1,\n",
       "  13866,\n",
       "  338,\n",
       "  385,\n",
       "  15278,\n",
       "  393,\n",
       "  16612,\n",
       "  263,\n",
       "  3414,\n",
       "  29892,\n",
       "  3300,\n",
       "  2859,\n",
       "  411,\n",
       "  385,\n",
       "  1881,\n",
       "  393,\n",
       "  8128,\n",
       "  4340,\n",
       "  3030,\n",
       "  29889,\n",
       "  14350,\n",
       "  263,\n",
       "  2933,\n",
       "  393,\n",
       "  7128,\n",
       "  2486,\n",
       "  1614,\n",
       "  2167,\n",
       "  278,\n",
       "  2009,\n",
       "  29889,\n",
       "  13,\n",
       "  13,\n",
       "  2277,\n",
       "  29937,\n",
       "  2799,\n",
       "  4080,\n",
       "  29901,\n",
       "  13,\n",
       "  31999,\n",
       "  30544,\n",
       "  30287,\n",
       "  31780,\n",
       "  31144,\n",
       "  30356,\n",
       "  30626,\n",
       "  30461,\n",
       "  30214,\n",
       "  31479,\n",
       "  30287,\n",
       "  30502,\n",
       "  30783,\n",
       "  30888,\n",
       "  30698,\n",
       "  233,\n",
       "  154,\n",
       "  136,\n",
       "  233,\n",
       "  187,\n",
       "  187,\n",
       "  31495,\n",
       "  30940,\n",
       "  30210,\n",
       "  233,\n",
       "  146,\n",
       "  146,\n",
       "  235,\n",
       "  194,\n",
       "  179,\n",
       "  13,\n",
       "  13,\n",
       "  2277,\n",
       "  29937,\n",
       "  10567,\n",
       "  29901,\n",
       "  13,\n",
       "  231,\n",
       "  191,\n",
       "  169,\n",
       "  233,\n",
       "  152,\n",
       "  169,\n",
       "  13,\n",
       "  13,\n",
       "  2277,\n",
       "  29937,\n",
       "  13291,\n",
       "  29901,\n",
       "  13,\n",
       "  231,\n",
       "  191,\n",
       "  169,\n",
       "  233,\n",
       "  152,\n",
       "  169,\n",
       "  30878,\n",
       "  235,\n",
       "  148,\n",
       "  154,\n",
       "  30548,\n",
       "  30210,\n",
       "  233,\n",
       "  154,\n",
       "  136,\n",
       "  233,\n",
       "  187,\n",
       "  187,\n",
       "  31495,\n",
       "  30940,\n",
       "  30577,\n",
       "  30287,\n",
       "  30392,\n",
       "  231,\n",
       "  191,\n",
       "  169,\n",
       "  233,\n",
       "  152,\n",
       "  169,\n",
       "  31831,\n",
       "  30267,\n",
       "  29871,\n",
       "  30810,\n",
       "  31780,\n",
       "  232,\n",
       "  145,\n",
       "  137,\n",
       "  30911,\n",
       "  233,\n",
       "  133,\n",
       "  163,\n",
       "  31347,\n",
       "  30210,\n",
       "  30626,\n",
       "  232,\n",
       "  163,\n",
       "  164,\n",
       "  30886,\n",
       "  30909,\n",
       "  29896,\n",
       "  29900,\n",
       "  29900,\n",
       "  29900,\n",
       "  30923,\n",
       "  30470,\n",
       "  30658,\n",
       "  30214,\n",
       "  233,\n",
       "  158,\n",
       "  193,\n",
       "  31412,\n",
       "  30406,\n",
       "  30732,\n",
       "  234,\n",
       "  158,\n",
       "  148,\n",
       "  234,\n",
       "  142,\n",
       "  180,\n",
       "  30330,\n",
       "  31140,\n",
       "  30613,\n",
       "  231,\n",
       "  192,\n",
       "  146,\n",
       "  30744,\n",
       "  30503,\n",
       "  232,\n",
       "  163,\n",
       "  164,\n",
       "  232,\n",
       "  161,\n",
       "  149,\n",
       "  31143,\n",
       "  31798,\n",
       "  29953,\n",
       "  29900,\n",
       "  29900,\n",
       "  30923,\n",
       "  30470,\n",
       "  29889,\n",
       "  2],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'labels': [-100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  231,\n",
       "  191,\n",
       "  169,\n",
       "  233,\n",
       "  152,\n",
       "  169,\n",
       "  30878,\n",
       "  235,\n",
       "  148,\n",
       "  154,\n",
       "  30548,\n",
       "  30210,\n",
       "  233,\n",
       "  154,\n",
       "  136,\n",
       "  233,\n",
       "  187,\n",
       "  187,\n",
       "  31495,\n",
       "  30940,\n",
       "  30577,\n",
       "  30287,\n",
       "  30392,\n",
       "  231,\n",
       "  191,\n",
       "  169,\n",
       "  233,\n",
       "  152,\n",
       "  169,\n",
       "  31831,\n",
       "  30267,\n",
       "  29871,\n",
       "  30810,\n",
       "  31780,\n",
       "  232,\n",
       "  145,\n",
       "  137,\n",
       "  30911,\n",
       "  233,\n",
       "  133,\n",
       "  163,\n",
       "  31347,\n",
       "  30210,\n",
       "  30626,\n",
       "  232,\n",
       "  163,\n",
       "  164,\n",
       "  30886,\n",
       "  30909,\n",
       "  29896,\n",
       "  29900,\n",
       "  29900,\n",
       "  29900,\n",
       "  30923,\n",
       "  30470,\n",
       "  30658,\n",
       "  30214,\n",
       "  233,\n",
       "  158,\n",
       "  193,\n",
       "  31412,\n",
       "  30406,\n",
       "  30732,\n",
       "  234,\n",
       "  158,\n",
       "  148,\n",
       "  234,\n",
       "  142,\n",
       "  180,\n",
       "  30330,\n",
       "  31140,\n",
       "  30613,\n",
       "  231,\n",
       "  192,\n",
       "  146,\n",
       "  30744,\n",
       "  30503,\n",
       "  232,\n",
       "  163,\n",
       "  164,\n",
       "  232,\n",
       "  161,\n",
       "  149,\n",
       "  31143,\n",
       "  31798,\n",
       "  29953,\n",
       "  29900,\n",
       "  29900,\n",
       "  30923,\n",
       "  30470,\n",
       "  29889,\n",
       "  2]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74b9de1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 2\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9504bbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.02k/1.02k [00:00<00:00, 85.4kB/s]\n",
      "Downloading pytorch_model.bin:   0%|                                                                                                                                                                                                | 0.00/300M [00:00<?, ?B/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sentencepiece as spm\n",
    "from transformers import GPTNeoForCausalLM, \n",
    "# tokenizer = spm.SentencePieceProcessor(model_file=\"mengzi_gpt.model\")\n",
    "model = GPTNeoForCausalLM.from_pretrained(\"Langboat/mengzi-gpt-neo-base\")\n",
    "\n",
    "def lm(prompt, top_k, top_p, max_length, repetition_penalty):\n",
    "    input_ids = torch.tensor(tokenizer.encode([prompt]), dtype=torch.long, device='cuda')\n",
    "    gen_tokens = model.generate(\n",
    "        input_ids,\n",
    "        do_sample=True,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,\n",
    "        max_length=max_length+len(prompt),\n",
    "        repetition_penalty=repetition_penalty)\n",
    "    result = tokenizer.decode(gen_tokens.tolist())[0]\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400a30e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"Langboat/mengzi-gpt-neo-base\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
